{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from wombat.engine import ml_model\n",
    "from wombat.engine import parse_input_description as parse_title\n",
    "from wombat.models import Item\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from wombat.models import dbsession, engine, ItemType, ItemAdjective\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams[\"figure.figsize\"] = (20,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = ml_model.canonical_df\n",
    "# split data into train and test group\n",
    "df['is_train'] = np.random.uniform(0, 1, len(df)) <= .75\n",
    "\n",
    "# copy of train before we delete the 'rent_per_week' and 'title' field. We want title \n",
    "# we will need these things before we make dummy variables\n",
    "df_full_training = df[df['is_train']==True]\n",
    "df_full_test = df[df['is_train']==False]\n",
    "\n",
    "# get one-hot columns for brands \n",
    "dummy_brands = pd.get_dummies(df['brand'])\n",
    "df = pd.concat([df, dummy_brands], axis = 1)\n",
    "df = df.drop('brand', axis = 1)\n",
    "\n",
    "# get one-hot columns for item_types\n",
    "dummified_items = pd.get_dummies(df['item_type'])\n",
    "df = pd.concat([df, dummified_items], axis = 1)\n",
    "df = df.drop('item_type', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get list of adjective features form database\n",
    "features_adj = [f.name for f in dbsession.query(ItemAdjective).all()]\n",
    "item_types   = [item.name for item in dbsession.query(ItemType).all()]\n",
    "\n",
    "tokenized_titles = []\n",
    "for title in df['title']:\n",
    "    parse_title.create_one_hot_row_adj(title, features_adj)\n",
    "    tokenized_titles.append(parse_title.create_one_hot_row_adj(title, features_adj))\n",
    "df_adj = pd.DataFrame(tokenized_titles, columns = features_adj)\n",
    "\n",
    "features_adj = [f.name for f in dbsession.query(ItemAdjective).all()]\n",
    "\n",
    "item_types   = [item.name for item in dbsession.query(ItemType).all()]\n",
    "\n",
    "tokenized_titles = []\n",
    "for text_array in df[['title', 'description']].values:\n",
    "    try:\n",
    "        text = ' '.join(text_array)\n",
    "    except TypeError:\n",
    "        text = title\n",
    "    #parse_title.create_one_hot_row_adj(text, features_adj)\n",
    "    tokenized_titles.append(parse_title.create_one_hot_row_adj(text, features_adj))\n",
    "df_adj = pd.DataFrame(tokenized_titles, columns = features_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_adj], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'cost', 'rent_per_week', 'description', 'is_train',\n",
       "       '  Dolce & Gabbana', ' Adrianna Papell', ' Alexia Admor',\n",
       "       ' Amanda Uprichard', ' Basix II',\n",
       "       ...\n",
       "       'gala', 'runway', 'ball', 'costume', 'iconic', 'cavier', 'peacock',\n",
       "       'florence', 'mermaid', 'jersey'],\n",
       "      dtype='object', length=1877)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.columns.drop(['rent_per_week', 'title', 'cost', 'is_train', 'description']) # just column names\n",
    "train, test = df[df['is_train']==True], df[df['is_train']==False]\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.93104469e-04,   0.00000000e+00,   7.36838975e-07, ...,\n",
       "         1.90523098e-05,   3.68606222e-04,   1.33384332e-03])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train['rent_per_week']\n",
    "#print(\"Shape of test df: {}\".format(test.shape))\n",
    "#print('Number of observations in the test data: {}'.format(df_full_test.shape))\n",
    "from sklearn import svm, linear_model\n",
    "\n",
    "#clf = svm.SVR() # didn't work. Predicted 43 for everything\n",
    "clf = RandomForestRegressor(n_jobs=2)\n",
    "clf.fit(train[features], train['rent_per_week'])\n",
    "rfr_predicted = clf.predict(test[features])\n",
    "#reg = linear_model.LinearRegression() # total crap\n",
    "#reg = linear_model.Ridge(alpha = .5) # comparable to rfr but much faster to compute\n",
    "#reg = linear_model.RidgeCV(alphas=[0.1, 1.0, 10.0]) # comparable to rfr \n",
    "#reg = linear_model.Lasso(alpha = 0.1)\n",
    "#reg = linear_model.ElasticNet(alpha=0.1) # comparable to rfr \n",
    "#reg = linear_model.RANSACRegressor(linear_model.LinearRegression()) # slow, did not finish, uses lots of cpu\n",
    "#reg = linear_model.TheilSenRegressor() # slow, did not finish, uses lots of cpu\n",
    "\n",
    "#reg = linear_model.HuberRegressor() # slow, did not finish, uses lots of cpu\n",
    "\n",
    "#reg.fit(train[features], train['rent_per_week'])\n",
    "#rfr_predicted = reg.predict(test[features])\n",
    "\n",
    "model_dir = '/home/patrick/Dropbox/insight/wombat/wombat/engine/stat_model_pickles'\n",
    "model_path = os.path.join(model_dir, 'rfr_v0.1_no_adj.pkl')\n",
    "joblib.dump(reg, model_path)\n",
    "#call this with: clf = joblib.load('huber_v0.1.pkl')\n",
    "#rfr_predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872\n",
      "1877\n"
     ]
    }
   ],
   "source": [
    "print(len(clf.feature_importances_))\n",
    "print(len(train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Create linear regression object for predicted vs measured\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "x = test['rent_per_week'].values.reshape(-1,1)\n",
    "y = np.array(rfr_predicted)\n",
    "\n",
    "# Train the model using the training sets\n",
    "reg.fit(x, y)\n",
    "# The coefficients\n",
    "print('Coefficients: ', reg.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % np.mean((reg.predict(x) - y) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % reg.score(x, y))\n",
    "\n",
    "# Plot outputs\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "ax.scatter(x = test['rent_per_week'], y = rfr_predicted)\n",
    "#stopping_value = np.minimum(test['rent_per_week'].max, np.maximum(rfr_predicted))\n",
    "stopping_value = 300\n",
    "ax.plot([0, stopping_value], [0, stopping_value], 'k--', lw=4)\n",
    "ax.set_title('Errors for RFR with no adjectives')\n",
    "ax.set_xlabel('Observed', fontsize=18)\n",
    "ax.set_ylabel('Predicted', fontsize=18)\n",
    "ax.plot(x, reg.predict(x), 'k--', color='blue', linewidth=3)\n",
    "\n",
    "ax.text(0, -70, 'Coefficients: {}'.format(reg.coef_), style='italic', fontsize=16,\n",
    "        bbox={'facecolor':'blue', 'alpha':0.2, 'pad':10})\n",
    "ax.text(110, -70, \"Mean squared error: %.2f\"\n",
    "      % np.mean((reg.predict(x) - y) ** 2), style='italic', fontsize=16,\n",
    "        bbox={'facecolor':'blue', 'alpha':0.2, 'pad':10})\n",
    "ax.text(220, -70, 'Variance score: %.2f' % reg.score(x, y), style='italic', fontsize=16,\n",
    "        bbox={'facecolor':'blue', 'alpha':0.2, 'pad':10})\n",
    "\n",
    "x = test['rent_per_week']\n",
    "df_full_test['predicted_rent'] = rfr_predicted\n",
    "df_full_test['error'] = df_full_test[['rent_per_week', 'predicted_rent']].sum(axis=1)\n",
    "df_error = df_full_test.loc[df_full_test['error']>0][['brand', 'item_type', 'title', 'error', 'description']].sort_values('error', ascending = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error.sort_values('error', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error[df_error['brand']=='Yves Saint Laurent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # make plotly plot\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "brands = df_full_training['brand'].values\n",
    "item_types = df_full_training['item_type'].values\n",
    "titles = df_full_training['title'].values\n",
    "labels = []\n",
    "for i in list(range(0, len(brands))):\n",
    "    labels.append(\"{}, {}, {}\".format(brands[i], item_types[i], titles[i]))\n",
    "\n",
    "data = [\n",
    "    go.Scatter(\n",
    "        x=test['rent_per_week'],\n",
    "        y=rfr_predicted,\n",
    "        mode='markers',\n",
    "        text=labels\n",
    "    )\n",
    "]\n",
    "layout = go.Layout(\n",
    "    title='Measured vs Predicted outcomes using Random Forest model'\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "plot_url = py.plot(fig, filename='meas-v-pred-rfr-2017-06-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "# Create linear regression object\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "x = test['rent_per_week'].values.reshape(-1,1)\n",
    "y = np.array(rfr_predicted)\n",
    "\n",
    "# Train the model using the training sets\n",
    "reg.fit(x, y)\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', reg.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % np.mean((reg.predict(x) - y) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % reg.score(x, y))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(x, y,  color='black')\n",
    "plt.plot(x, reg.predict(x), color='blue',\n",
    "         linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
